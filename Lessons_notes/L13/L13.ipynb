{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L13 08/04/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection: Proximity Based Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types:\n",
    "- Distance Based\n",
    "- Density Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base idea is the fact that normal points have close neighbors while anomalies are located far from other points.  \n",
    "The general approach is to compute the neighborhood for each data record and then analyze it to determine wheter data record is anomaly or not.  \n",
    "\n",
    "Advantages:\n",
    "- can be used in unsupervised or semi-supervised setting  \n",
    "\n",
    "Drabacks:\n",
    "- If normal  points do not have sufficient number of neighbors the techniques may fail\n",
    "- Computationally expensive\n",
    "- In high dimensional spaces, data is sparse and the concept of similarity may not be meaningful anymore, this may lead to any data record that can be considered as a potential outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Distance based approaches:\n",
    "\n",
    "A point $O^*$ in a dataset is a distance based $DB(p,d)$ outlier is at least aa fraction p of the points in the data set lies greater thaan distance d from the point $O^*$\n",
    "\n",
    "#### Nearest Neighbor (NN) Approach:\n",
    "- For each data point $O$ compute the distance to the $k^{th}$ nearest neighbor $d_k$\n",
    "- sort all data points according to the distance $d_k$\n",
    "- Outliers are points that have the largest distance $d_k$ and therefore are located in the more sparse neighborhoods\n",
    "- usually data points that have top $n%$ distance $d_k$ are identified as outliers ($n$ is a user parameter)\n",
    "  \n",
    "Not suitable for datasets taht have modes with varying density\n",
    "\n",
    "Strengths and weaknesses:\n",
    "- Simple\n",
    "- Expensive, $O(n^2)$\n",
    "- sensitive to parameters ($k$ and $n%$)\n",
    "- sensitive to variations in density\n",
    "- distance becomes less meaningful in high-dimensional space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Density based Approaches\n",
    "Compute local densities of particular regions and declare instances in low density region as potential anomalies, using:\n",
    "- Local Outlier Factor (LOF)\n",
    "- Connectivity Outlier Factor (COF)\n",
    "- Multi-Granularity Deviation Factor (MDEF)\n",
    "\n",
    "#### Local Outlier Factor (LOF):\n",
    "\n",
    "![alt text](image.png)\n",
    "\n",
    "In the example, in the distance based approach, $O_2$ is not considered as outlier, while the  LOF approach finds both $O_1$ and  $O_2$ as outliers.  \n",
    "\n",
    "Distance based approach may consider  $O_2$ as outlier, but LOF approach does not.  \n",
    "\n",
    "Algorithm:\n",
    "- For each data point $p$ compute the distance to the $k^th$ nearest neighbor $d_k$\n",
    "- Compute reachability distance for each data example  with respect to data example  as $reach-dist(p,q) = max[d_k, d(p,q)]$, this distance represents how \"reachable\" point B is from point A, considering the local density around point A.\n",
    "- Compute local reachability density of data example as inverse of the average reachability distance based  on the $MinPts$ nearest neighbors of data example $q$, Essentially, it quantifies how densely packed the neighbors of the point are.\n",
    "— LOF($q$) is the ratio of average local reachability density of $q$’s k-nearest neighbors and local reachability density of the data record $q$\n",
    "\n",
    "$$lrd(q) = \\frac{MinPts}{\\sum_preach-dist_{MinPts}(p,q)}$$\n",
    "$$LOF(q) = \\frac{1}{MinPts} \\sum_p\\frac{lrd(p)}{lrd(q)}$$\n",
    "\n",
    "Strengths and Weaknesses:\n",
    "- Simple\n",
    "- expensive, $O(n^2)$\n",
    "- sensitive to parameters $k$ and $MinPts$\n",
    "- density becomes less meaningful in high-dimensional space\n",
    "\n",
    "#### Connectivity Outlier Factor (COF)\n",
    "\n",
    "Outliers are points p where average caining diataance $ac-dist_{kNN(p)}(p)$ is larger than the average chaining distance of their k-nearest neighborhood $kNN(p)$\n",
    "$$ac-dist_{kNN(p)}(p) = \\sum_{i=1}^r\\frac{2(r-1)}{r(r-i)} dist(e_i)$$\n",
    "\n",
    "OF identifies outliers as points whose neighborhoods is sparser than the neighborhoods of their neighbors\n",
    "\n",
    "![alt text](image-1.png)\n",
    "![alt text](image-2.png)\n",
    "![alt text](image-3.png)\n",
    "![alt text](image-4.png)\n",
    "![alt text](image-5.png)\n",
    "\n",
    "We average cost descriptions!  \n",
    "We would like to give more  wights to points closer to the point $p_1$, the smaller $ac-dist$, the more compact is the neighborhood $G$ of $p$  \n",
    "COF is computed as the ration of the $ac-dit$ (average chaining distance) at the point and the mean $ac-dist$ at the point's neighborhood, similar idea as the LOF approach, a point is an outlier if its neighborhood is less compact than the neighborhood of its neighors.\n",
    "\n",
    "$$COF_k(p) = \\frac{ac-dist_{kNN(p)\\cup }(p)}{\\frac{1}{k} \\sum_{o \\in kNN(p)} ac - dist_{kNN(o) \\cup  o}(o)}$$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
